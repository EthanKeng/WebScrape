{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished Proxy\n",
      "finished get req\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "finished get req\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "finished get req\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-fa9c25725ede>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    134\u001b[0m             \u001b[0mstar\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"n/a\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m             \u001b[0mreview\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"n/a\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m         \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreview\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlink\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;31m#print(\"name: \"+name+\", star: \"+str(star)+\", review: \"+str(review)+\", link: \"+link)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "# Install a pip package in the current Jupyter kernel\n",
    "import sys\n",
    "!{sys.executable} -m pip install fake_useragent\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import random,time\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "from urllib.request import Request, urlopen\n",
    "from fake_useragent import UserAgent\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.core.display import clear_output\n",
    "# Here I provide some proxies for not getting caught while scraping\n",
    "ua = UserAgent() # From here we generate a random user agent\n",
    "proxies = [] # Will contain proxies [ip, port]\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "  # Retrieve latest proxies\n",
    "  proxies_req = Request('https://www.sslproxies.org/')\n",
    "  proxies_req.add_header('User-Agent', ua.random)\n",
    "  proxies_doc = urlopen(proxies_req).read().decode('utf8')\n",
    "\n",
    "  soup = BeautifulSoup(proxies_doc, 'html.parser')\n",
    "  proxies_table = soup.find(id='proxylisttable')\n",
    "\n",
    "  # Save proxies in the array\n",
    "  for row in proxies_table.tbody.find_all('tr'):\n",
    "    proxies.append({\n",
    "      'ip':   row.find_all('td')[0].string,\n",
    "      'port': row.find_all('td')[1].string\n",
    "    })\n",
    "\n",
    "  # Choose a random proxy\n",
    "  proxy_index = random_proxy()\n",
    "  proxy = proxies[proxy_index]\n",
    "\n",
    "  for n in range(1, 10):\n",
    "    req = Request('http://icanhazip.com')\n",
    "    req.set_proxy(proxy['ip'] + ':' + proxy['port'], 'http')\n",
    "\n",
    "    # Every 10 requests, generate a new proxy\n",
    "    if n % 10 == 0:\n",
    "      proxy_index = random_proxy()\n",
    "      proxy = proxies[proxy_index]\n",
    "\n",
    "    # Make the call\n",
    "    try:\n",
    "      my_ip = urlopen(req).read().decode('utf8')\n",
    "      print('#' + str(n) + ': ' + my_ip)\n",
    "      clear_output(wait = True)\n",
    "    except: # If error, delete this proxy and find another one\n",
    "      del proxies[proxy_index]\n",
    "      print('Proxy ' + proxy['ip'] + ':' + proxy['port'] + ' deleted.')\n",
    "      proxy_index = random_proxy()\n",
    "      proxy = proxies[proxy_index]\n",
    "\n",
    "# Retrieve a random index proxy (we need the index to delete it if not working)\n",
    "def random_proxy():\n",
    "  return random.randint(0, len(proxies) - 1)\n",
    "if __name__ == '__main__':\n",
    "  main()\n",
    "\n",
    "#if os.path.exists('./amazon') == False:\n",
    "#    os.mkdir('./amazon')\n",
    "user_agent_list = (\n",
    "   #Chrome\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 5.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.2; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.90 Safari/537.36',\n",
    "    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/44.0.2403.157 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.3; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/60.0.3112.113 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/57.0.2987.133 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/55.0.2883.87 Safari/537.36',\n",
    "    #Firefox\n",
    "    'Mozilla/4.0 (compatible; MSIE 9.0; Windows NT 6.1)',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; WOW64; Trident/5.0)',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (Windows NT 6.2; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (Windows NT 10.0; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.0; Trident/5.0)',\n",
    "    'Mozilla/5.0 (Windows NT 6.3; WOW64; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0)',\n",
    "    'Mozilla/5.0 (Windows NT 6.1; Win64; x64; Trident/7.0; rv:11.0) like Gecko',\n",
    "    'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; WOW64; Trident/6.0)',\n",
    "    'Mozilla/5.0 (compatible; MSIE 10.0; Windows NT 6.1; Trident/6.0)',\n",
    "    'Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 5.1; Trident/4.0; .NET CLR 2.0.50727; .NET CLR 3.0.4506.2152; .NET CLR 3.5.30729)'\n",
    ")\n",
    "\n",
    " # Make a get request\n",
    "user_agent = random.choice(user_agent_list)\n",
    "headers= {'User-Agent': user_agent, \"Accept-Language\": \"en-US, en;q=0.5\"}\n",
    "proxy = random.choice(proxies)\n",
    "print(\"finished Proxy\")\n",
    "\n",
    "main_url= \"https://www.amazon.co.jp/s?k=youtuber+%E6%92%AE%E5%BD%B1%E3%82%AD%E3%83%83%E3%83%88&i=electronics&rh=n%3A3210981%2Cp_n_price_fma%3A401024011&s=review-rank&dc&page={}&language=en&crid=2MDDQ965PQRDN&qid=1609800358&rnid=401022011&sprefix=youtuber%2Caps%2C293&ref=sr_pg_2\"\n",
    "Url_Pages = []\n",
    "for i in range(3):\n",
    "    url = main_url.format(i+1)\n",
    "    Url_Pages.append(url)\n",
    "\n",
    "file = open('results.csv', 'w')\n",
    "writer = csv.writer(file)\n",
    " \n",
    "# write title row\n",
    "writer.writerow(['name', 'star', 'review','link'])    \n",
    "\n",
    "    #my_dict = {\"name\":[],\"price\":[],\"rate\":[],\"reviews\":[],\"stars\": [],\"links\": [] }\n",
    "i = 1\n",
    "for url in Url_Pages:\n",
    "    response = requests.get(url, headers=headers,proxies=proxy)\n",
    "    print(\"finished get req\")\n",
    "    soup = BeautifulSoup(response.text, 'lxml')\n",
    "    group = soup.find_all('div', class_='a-section a-spacing-medium')\n",
    "    for g in group:\n",
    "        href = g.find(\"h2\").find(\"a\").get(\"href\")\n",
    "        link= 'https://amazon.co.jp'+href\n",
    "        #my_dict[\"links\"].append(link)\n",
    "        name = g.find(\"h2\").getText()\n",
    "        #my_dict[\"name\"].append(name)\n",
    "        try:\n",
    "            star = g.find(\"i\").getText()\n",
    "            #my_dict[\"stars\"].append(star)\n",
    "            review = g.find(\"span\",class_=\"a-size-base\")\n",
    "            #my_dict[\"reviews\"].append(review)            \n",
    "        except:\n",
    "            star=\"n/a\"\n",
    "            review=\"n/a\"\n",
    "        writer.writerow([name.encode('utf-8'), star.encode('utf-8'), review.encode('utf-8'),link.encode('utf-8')])\n",
    "\n",
    "        #print(\"name: \"+name+\", star: \"+str(star)+\", review: \"+str(review)+\", link: \"+link)\n",
    "        print(i)\n",
    "        i=i+1\n",
    "# with open(\"results.csv\", \"w\") as outfile:\n",
    "#    writer = csv.writer(outfile)\n",
    "#    writer.writerow(my_dict.keys())\n",
    "#    writer.writerows(zip(*my_dict.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_dict\n",
    "with open(\"results.csv\", \"w\") as outfile:\n",
    "   writer = csv.writer(outfile)\n",
    "   writer.writerow(my_dict.keys())\n",
    "   writer.writerows(zip(*my_dict.values()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched: 4.6 \n",
      "matched: 4.8 \n",
      "matched: 4.5 \n",
      "matched: 4.5 \n",
      "matched: 4.4 \n",
      "matched: 4.3 \n",
      "matched: 4.4 \n",
      "matched: 4.4 \n",
      "matched: 4.3 \n",
      "matched: 4.3 \n",
      "matched: 4.4 \n",
      "matched: 4.4 \n",
      "matched: 4.2 \n",
      "matched: 4.5 \n",
      "matched: 4.2 \n",
      "matched: 4.1 \n",
      "matched: 4.1 \n",
      "matched: 4.0 \n",
      "matched: 4.2 \n",
      "matched: 4.1 \n",
      "matched: 4.0 \n",
      "matched: 4.0 \n",
      "matched: 4.0 \n",
      "matched: 4.2 \n",
      "matched: 4.5 \n",
      "matched: 4.8 \n",
      "matched: 4.2 \n",
      "matched: 4.0 \n",
      "matched: 3.9 \n",
      "matched: 4.0 \n",
      "matched: 3.8 \n",
      "matched: 3.9 \n",
      "matched: 3.9 \n",
      "matched: 3.9 \n",
      "matched: 3.8 \n",
      "matched: 3.8 \n",
      "matched: 3.9 \n",
      "matched: 3.8 \n",
      "matched: 3.9 \n",
      "matched: 4.0 \n",
      "matched: 3.6 \n",
      "matched: 4.3 \n",
      "matched: 3.6 \n",
      "matched: 3.6 \n",
      "matched: 3.9 \n",
      "matched: 4.5 \n",
      "matched: 3.5 \n",
      "matched: 5.0 \n",
      "matched: 5.0 \n",
      "matched: 5.0 \n",
      "matched: 3.4 \n",
      "matched: 4.5 \n",
      "matched: 4.8 \n",
      "matched: 4.2 \n",
      "matched: 3.4 \n",
      "matched: 3.3 \n",
      "matched: 3.3 \n",
      "matched: 4.0 \n",
      "matched: 3.3 \n",
      "60\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "i =1\n",
    "with open(\"results.csv\", mode=\"r\", encoding=\"utf-8\") as rf:\n",
    "    reader = csv.reader(rf)\n",
    "    # ヘッダー行を飛ばす\n",
    "    next(reader)\n",
    "\n",
    "    with open(\"results_new.csv\", mode=\"w\", encoding=\"utf-8\") as wf:\n",
    "        writer = csv.writer(wf)\n",
    "        writer.writerow(['name', 'star', 'review','link'])    \n",
    "          # 価格を変更する\n",
    "        for line in reader:\n",
    "            #print(line)\n",
    "            if not not line:\n",
    "                m = re.match(\"(.+?)(\\d.+?)(?=out of 5 stars)\", line[1]).group(2)\n",
    "                print(\"matched:\",m)\n",
    "                k=re.match(\"(.+?>)(.+?)(<.+?)\",line[2]).group(2)\n",
    "                writer.writerow([line[0], str(m), str(k),line[3]])\n",
    "                i+=1\n",
    "\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results_new.csv\", mode=\"w\", encoding=\"utf-8\") as wf:\n",
    "    writer = csv.writer(wf)\n",
    "    writer.writerow(['name', 'star', 'review','link'])    \n",
    "    for line in range(10):\n",
    "        if not not line:\n",
    "          writer.writerow([1, line+1, line+2,line+3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apple\n",
      "orange\n",
      "grape\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "rawdata = [[\"id\", \"menu\", \"price\"],\n",
    " [1, \"apple\", 100],\n",
    " [2, \"orange\", 100],\n",
    " [3, \"grape\", 200]]\n",
    "i=1\n",
    "# CSVファイルを作成\n",
    "with open(\"menu.csv\", mode=\"w\", encoding=\"utf-8\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(rawdata)\n",
    "\n",
    "# 作成したCSVを読み込む\n",
    "with open(\"menu.csv\", mode=\"r\", encoding=\"utf-8\") as rf:\n",
    "    reader = csv.reader(rf)\n",
    "    # ヘッダー行を飛ばす\n",
    "    next(reader)\n",
    "    with open(\"menu_new.csv\", mode=\"w\", encoding=\"utf-8\") as wf:\n",
    "        writer = csv.writer(wf)\n",
    "        writer.writerow([\"id\", \"menu\", \"price(+tax)\"])\n",
    "        # 価格を変更する\n",
    "        for line in reader:\n",
    "            if not not line:\n",
    "                print(line[1])\n",
    "                priceintax = int(20) * 1.1\n",
    "                writer.writerow([line[0], line[1], int(priceintax)])\n",
    "                i=+1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
